# ğŸ”§ ZarzÄ…dzanie zasobami w Kubernetes: Resources, Limits i QoS

## ğŸ¯ Cel zadania
Celem zadania jest zrozumienie jak dziaÅ‚ajÄ… limity zasobÃ³w w Kubernetes, co siÄ™ dzieje gdy pod przekroczy przydzielone limity oraz jak dziaÅ‚a Quality of Service (QoS).

## ğŸ“š Teoria

### Resources w Kubernetes
- **Requests**: Minimalna iloÅ›Ä‡ zasobÃ³w, ktÃ³rej pod potrzebuje
- **Limits**: Maksymalna iloÅ›Ä‡ zasobÃ³w, ktÃ³rej pod nie moÅ¼e przekroczyÄ‡
- **CPU**: Mierzony w jednostkach CPU (1 CPU = 1 vCPU/Core)
  - MoÅ¼na uÅ¼ywaÄ‡ milicore (m), np. 100m = 0.1 CPU
- **Memory**: Mierzona w bajtach
  - MoÅ¼na uÅ¼ywaÄ‡ sufixÃ³w: Ki, Mi, Gi
  - PrzykÅ‚ad: 256Mi, 1Gi

#### Quality of Service (QoS) Classes
1. **Guaranteed**
   - Requests = Limits dla CPU i pamiÄ™ci
   - NajwyÅ¼szy priorytet, najmniejsza szansa na usuniÄ™cie
   
2. **Burstable**
   - Requests < Limits
   - Åšredni priorytet
   
3. **BestEffort**
   - Brak zdefiniowanych Requests i Limits
   - NajniÅ¼szy priorytet, pierwsze do usuniÄ™cia

## ğŸ“ Zadanie 1: Pod z gwarantowanymi zasobami (QoS: Guaranteed)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kuard-guaranteed
spec:
  containers:
  - name: kuard
    image: gcr.io/kuar-demo/kuard-amd64:1
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "64Mi"
        cpu: "100m"
```

## ğŸ“ Zadanie 2: Pod z elastycznymi zasobami (QoS: Burstable)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kuard-burstable
spec:
  containers:
  - name: kuard
    image: gcr.io/kuar-demo/kuard-amd64:1
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "128Mi"
        cpu: "200m"
```

## ğŸ“ Zadanie 3: Pod bez limitÃ³w (QoS: BestEffort)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kuard-besteffort
spec:
  containers:
  - name: kuard
    image: gcr.io/kuar-demo/kuard-amd64:1
```

## ğŸ“ Zadanie 4: Test OOM (Out of Memory)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kuard-oom
spec:
  containers:
  - name: kuard
    image: gcr.io/kuar-demo/kuard-amd64:1
    resources:
      requests:
        memory: "50Mi"
        cpu: "100m"
      limits:
        memory: "100Mi"
        cpu: "200m"
```

### Kroki testowe:

> [!IMPORTANT]  
> Potrzebujesz do tego zadania dwÃ³ch terminali

1. OtwÃ³rz pierwszy terminal i uruchom monitoring podÃ³w:
```bash
kubectl get pods -w
```

2. W drugim terminalu utwÃ³rz pod:
```bash
kubectl apply -f kuard-oom.yaml
```

3. Przekieruj port:
```bash
kubectl port-forward pod/kuard-oom 8080:8080
```

4. OtwÃ³rz aplikacjÄ™ w przeglÄ…darce (http://localhost:8080)

5. PrzejdÅº do zakÅ‚adki `Memory`

6. Obserwuj pierwszy terminal z `kubectl get pods -w` i zacznij klikaÄ‡ `Grow` kilka razy, aby zwiÄ™kszyÄ‡ zuÅ¼ycie pamiÄ™ci powyÅ¼ej 100Mi

7. W pierwszym terminalu zobaczysz:
```
NAME        READY   STATUS    RESTARTS   AGE
kuard-oom   1/1     Running   0          30s
kuard-oom   1/1     Running   1          45s    # Pod zostaÅ‚ zrestartowany
```

8. Aby zobaczyÄ‡ szczegÃ³Å‚y OOM:
```bash
kubectl describe pod kuard-oom
```

Zobaczysz w Events:
```
Type     Reason     Age   From               Message
----     ------     ----  ----               -------
Normal   Pulled     2m    kubelet            Container image "gcr.io/kuar-demo/kuard-amd64:1" already present on machine
Normal   Created    2m    kubelet            Created container kuard
Normal   Started    2m    kubelet            Started container kuard
Warning  OOMKilled  1m    kubelet            Container kuard was killed due to OOM (Out of Memory)
Normal   Pulling    1m    kubelet            Container image "gcr.io/kuar-demo/kuard-amd64:1" already present on machine
```

## ğŸ“Š Sprawdzanie QoS Class

```bash
# SprawdÅº QoS Class dla poda
kubectl get pod kuard-guaranteed -o yaml | grep qosClass
kubectl get pod kuard-burstable -o yaml | grep qosClass
kubectl get pod kuard-besteffort -o yaml | grep qosClass
```

## ğŸ“‹ Events w Kubernetes

### Co to sÄ… Events?
Events w Kubernetes to obiekt API, ktÃ³ry dostarcza informacji o tym, co dzieje siÄ™ wewnÄ…trz klastra. Events sÄ… automatycznie generowane gdy:
- Pod jest tworzony/usuwany
- WystÄ™pujÄ… bÅ‚Ä™dy (np. OOMKilled)
- Zmienia siÄ™ stan zasobÃ³w
- NastÄ™pujÄ… zmiany w schedulingu
- WystÄ™pujÄ… problemy z pull'owaniem obrazÃ³w

### Podstawowe komendy
```bash
# PokaÅ¼ wszystkie wydarzenia w klastrze
kubectl get events

# PokaÅ¼ wydarzenia posortowane od najnowszych
kubectl get events --sort-by=.metadata.creationTimestamp

# PokaÅ¼ wydarzenia w czasie rzeczywistym
kubectl get events -w

# PokaÅ¼ wydarzenia dla konkretnego namespace
kubectl get events -n <namespace>

# PokaÅ¼ wydarzenia zwiÄ…zane z konkretnym podem
kubectl get events --field-selector involvedObject.name=<pod-name>

# PokaÅ¼ wydarzenia z ostatnich 5 minut
kubectl get events --since=5m

# Format wyjÅ›cia jako tabela z wybranymi kolumnami
kubectl get events --output=custom-columns=TIMESTAMP:.metadata.creationTimestamp,TYPE:.type,REASON:.reason,MESSAGE:.message
```

### PrzykÅ‚ad monitorowania OOM przez Events

1. Uruchom monitoring eventÃ³w w pierwszym terminalu:
```bash
kubectl get events -w --field-selector involvedObject.name=kuard-oom
```

2. W drugim terminalu utwÃ³rz pod i wykonaj test OOM z poprzedniego zadania.

3. Zobaczysz sekwencjÄ™ eventÃ³w:
```
LAST SEEN   TYPE     REASON      OBJECT          MESSAGE
0s          Normal   Scheduled   pod/kuard-oom   Successfully assigned default/kuard-oom to node1
1s          Normal   Pulling     pod/kuard-oom   Pulling image "gcr.io/kuar-demo/kuard-amd64:1"
10s         Normal   Pulled      pod/kuard-oom   Successfully pulled image "gcr.io/kuar-demo/kuard-amd64:1"
11s         Normal   Created     pod/kuard-oom   Created container kuard
12s         Normal   Started     pod/kuard-oom   Started container kuard
35s         Warning  OOMKilled   pod/kuard-oom   Container kuard was killed due to OOM (Out of Memory)
36s         Normal   Pulling     pod/kuard-oom   Pulling image "gcr.io/kuar-demo/kuard-amd64:1"
```

### Typy EventÃ³w
- **Normal**: Standardowe operacje (utworzenie poda, pull image)
- **Warning**: Problemy i bÅ‚Ä™dy (OOMKilled, ImagePullBackOff)

### NajczÄ™stsze Reasons w Events
| Reason | Opis |
|--------|------|
| Created | Kontener zostaÅ‚ utworzony |
| Started | Kontener zostaÅ‚ uruchomiony |
| Pulled | Obraz zostaÅ‚ pobrany |
| Failed | WystÄ…piÅ‚ bÅ‚Ä…d |
| Killing | Kontener jest zabijany |
| OOMKilled | Przekroczono limit pamiÄ™ci |
| BackOff | Problem z uruchomieniem kontenera |
| Unhealthy | Nieudane health checki |

### Dobre praktyki uÅ¼ywania Events

1. **Monitoring**
   - UÅ¼ywaj `-w` do monitorowania w czasie rzeczywistym
   - Filtruj events dla konkretnych obiektÃ³w
   - Zwracaj uwagÄ™ na Warning events

2. **Debugowanie**
   - Sprawdzaj events jako pierwszy krok debugowania
   - ÅÄ…cz informacje z events z logami podÃ³w
   - UÅ¼ywaj `--since` do zawÄ™Å¼enia czasowego

3. **Agregacja**
   - Przechowuj events dÅ‚ugoterminowo (domyÅ›lnie sÄ… usuwane po godzinie)
   - UÅ¼ywaj narzÄ™dzi jak Prometheus/Grafana do agregacji
   - Ustaw alerty na podstawie critical events

4. **Sortowanie i filtrowanie**
   ```bash
   # Sortowanie po czasie
   kubectl get events --sort-by='.lastTimestamp'
   
   # Sortowanie po typie
   kubectl get events --sort-by='.type'
   
   # Filtrowanie po typie Warning
   kubectl get events --field-selector type=Warning
   
   # ÅÄ…czenie filtrÃ³w
   kubectl get events --field-selector type=Warning,reason=OOMKilled
   ```

### Events w praktyce debugowania OOM

1. **Przed testem**
   ```bash
   # Terminal 1: Monitoring ogÃ³lny
   kubectl get pods -w
   
   # Terminal 2: Monitoring eventÃ³w
   kubectl get events -w --field-selector involvedObject.name=kuard-oom
   
   # Terminal 3: Port forward i testy
   kubectl port-forward pod/kuard-oom 8080:8080
   ```

2. **Po wystÄ…pieniu OOM**
   ```bash
   # SprawdÅº historiÄ™ eventÃ³w
   kubectl get events --field-selector involvedObject.name=kuard-oom --sort-by='.lastTimestamp'
   
   # SprawdÅº szczegÃ³Å‚y poda
   kubectl describe pod kuard-oom
   ```

3. **Analiza**
   - SprawdÅº czas miÄ™dzy utworzeniem a OOMKilled
   - Zobacz sekwencjÄ™ eventÃ³w przed OOM
   - Zweryfikuj czy sÄ… inne warningi

## â— NajczÄ™stsze problemy

| Problem | RozwiÄ…zanie |
|---------|-------------|
| Pod ciÄ…gle siÄ™ restartuje | SprawdÅº logi i describe pod, prawdopodobnie OOMKilled |
| Pod nie startuje | SprawdÅº czy node ma wystarczajÄ…ce zasoby |
| Aplikacja dziaÅ‚a wolno | ZwiÄ™ksz requests/limits dla CPU |
| Pod zostaÅ‚ usuniÄ™ty | SprawdÅº QoS Class i dostÄ™pne zasoby na nodzie |

## âœ… Dobre praktyki

1. **Zawsze definiuj requests i limits**
   - Pomaga w planowaniu zasobÃ³w
   - Chroni przed przeciÄ…Å¼eniem node'a
   
2. **Monitoruj zuÅ¼ycie zasobÃ³w**
   - UÅ¼ywaj narzÄ™dzi jak Prometheus i Grafana
   - Regularnie sprawdzaj metryki
   
3. **Dobierz odpowiedniÄ… klasÄ™ QoS**
   - Dla krytycznych aplikacji uÅ¼ywaj Guaranteed
   - Dla mniej waÅ¼nych moÅ¼esz uÅ¼yÄ‡ Burstable
   - BestEffort tylko dla najmniej waÅ¼nych zadaÅ„
   
4. **Testuj limity**
   - SprawdÅº jak aplikacja zachowuje siÄ™ przy rÃ³Å¼nych limitach
   - Testuj scenariusze OOM
   - Monitoruj restarty podÃ³w

## ğŸ“ Podsumowanie
- Resources pomagajÄ… efektywnie zarzÄ…dzaÄ‡ zasobami klastra
- QoS Classes okreÅ›lajÄ… priorytety podÃ³w
- OOM Kill chroni node przed przeciÄ…Å¼eniem
- WÅ‚aÅ›ciwe ustawienie limitÃ³w jest kluczowe dla stabilnoÅ›ci aplikacji

## ğŸ” Co dzieje siÄ™ podczas OOM Kill?
1. Pod przekracza limit pamiÄ™ci (100Mi w naszym przykÅ‚adzie)
2. Kubernetes wykrywa przekroczenie limitu
3. Container runtime zabija proces (OOM Kill)
4. Kubelet wykrywa Å›mierÄ‡ kontenera
5. Ze wzglÄ™du na domyÅ›lnÄ… politykÄ™ restartowÄ… (Always), pod zostaje zrestartowany
6. W `kubectl get pods -w` widzimy zwiÄ™kszenie liczby restartÃ³w
7. CaÅ‚y proces jest widoczny w czasie rzeczywistym dziÄ™ki fladze `-w`
